{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ff23e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 04:52:41.119139: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-17 04:52:41.606718: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-17 04:52:42.023795: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1731819162.335000   17138 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1731819162.428556   17138 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-17 04:52:43.267622: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "# running on a vm, no gpu\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from music21 import *\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from fractions import Fraction\n",
    "import json\n",
    "import pandas as pd\n",
    "import pretty_midi\n",
    "from typing import Optional\n",
    "\n",
    "# constants\n",
    "NUM_PIANO_KEYS = 88\n",
    "A0_MIDI_OFFSET = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b112c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6445"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notes = []\n",
    "offsets = []\n",
    "durations = []\n",
    "\n",
    "# change path to read in different midi files\n",
    "for file in glob.glob('./*.mid', recursive=True):\n",
    "    try:\n",
    "        mid = converter.parse(file)\n",
    "    except:\n",
    "        print(file)\n",
    "    notes_to_parse = None\n",
    "    prev_offset = 0\n",
    "          \n",
    "    notes_to_parse = mid.flatten().notes\n",
    "    \n",
    "    for element in notes_to_parse:\n",
    "        if isinstance(element, note.Note):\n",
    "            # One hot encoding of pitch by piano key\n",
    "            arr = np.zeros(NUM_PIANO_KEYS)\n",
    "            try:\n",
    "                arr[element.pitch.midi - A0_MIDI_OFFSET] = 1\n",
    "            except IndexError:\n",
    "                # removes files that had note outside the range of a piano\n",
    "                os.remove(file)\n",
    "                break\n",
    "                \n",
    "        \n",
    "            notes.append(arr)\n",
    "            \n",
    "            durations.append(str(element.quarterLength))\n",
    "            \n",
    "            offsets.append(round(float(element.offset - prev_offset), 3))\n",
    "            prev_offset = element.offset\n",
    "            \n",
    "        elif isinstance(element, chord.Chord):\n",
    "            # if an element is a chord, encode each note separately\n",
    "            isFirstNote = True\n",
    "            for n in element:\n",
    "                arr = np.zeros(NUM_PIANO_KEYS)\n",
    "                try:\n",
    "                    arr[n.pitch.midi - A0_MIDI_OFFSET] = 1\n",
    "                except IndexError:\n",
    "                    try:\n",
    "                        os.remove(file)\n",
    "                        break\n",
    "                    except FileNotFoundError:\n",
    "                        break\n",
    "                    \n",
    "                notes.append(arr)\n",
    "                \n",
    "                durations.append(str(n.quarterLength))\n",
    "                \n",
    "                # offset of first note is chord offset, offset of other notes is 0\n",
    "                if isFirstNote:\n",
    "                    offsets.append(round(float(element.offset - prev_offset), 3))\n",
    "                    prev_offset = element.offset\n",
    "                    isFirstNote = False\n",
    "                else:\n",
    "                    offsets.append(float(0))\n",
    "\n",
    "notes = np.asarray(notes)\n",
    "len(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8fabed87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionaries to one hot encode and decode\n",
    "duration_map = {d: i for i, d in enumerate(sorted(set(durations)))}\n",
    "reverse_duration = {i: d for i, d in enumerate(sorted(set(durations)))}\n",
    "offset_map = {o: i for i, o in enumerate(sorted(set(offsets)))}\n",
    "reverse_offset = {i: o for i, o in enumerate(sorted(set(offsets)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2df88b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0.25': 0,\n",
       " '0.5': 1,\n",
       " '0.75': 2,\n",
       " '1.0': 3,\n",
       " '1.5': 4,\n",
       " '2.0': 5,\n",
       " '2/3': 6,\n",
       " '3.0': 7}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duration_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96601a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 0, 0.5: 1, 1.0: 2, 1.5: 3, 2.0: 4, 3.0: 5}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c52f473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encodes the durations\n",
    "temp = []\n",
    "size = len(duration_map)\n",
    "for duration in durations:\n",
    "    arr = np.zeros(size)\n",
    "    arr[duration_map[duration]] = 1\n",
    "    temp.append(arr)\n",
    "durations = np.asarray(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af03bd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encodes the offsets\n",
    "temp = []\n",
    "size = len(offset_map)\n",
    "for offset in offsets:\n",
    "    arr = np.zeros(size)\n",
    "    try:\n",
    "        arr[offset_map[offset]] = 1\n",
    "    except IndexError:\n",
    "        print(offset, offset_map[offset])\n",
    "        print(arr[offset_map[offset]])\n",
    "    temp.append(arr)\n",
    "offsets = np.asarray(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c0650da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combines the three vectors per note into a single one\n",
    "train_notes = np.concatenate([notes, durations, offsets], axis = 1)\n",
    "\n",
    "# creates groupings of 50 inputs notes for each output note for training\n",
    "seq_length = 50\n",
    "inputs = []\n",
    "note_outputs = []\n",
    "duration_outputs = []\n",
    "offset_outputs = []\n",
    "for i in range(len(notes) - seq_length):\n",
    "    inputs.append(train_notes[i : i + seq_length])\n",
    "    \n",
    "    note_outputs.append(notes[i + seq_length])\n",
    "    duration_outputs.append(durations[i + seq_length])\n",
    "    offset_outputs.append(offsets[i + seq_length])\n",
    "    \n",
    "input_size = len(inputs)\n",
    "inputs = np.asarray(inputs)\n",
    "inputs.reshape(input_size, seq_length, len(train_notes[0]))\n",
    "\n",
    "note_outputs = np.asarray(note_outputs)\n",
    "duration_outputs = np.asarray(duration_outputs)\n",
    "offset_outputs = np.asarray(offset_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "321fb96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 50, 102)]            0         []                            \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               (None, 512)                  1259520   ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 512)                  0         ['lstm_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 256)                  131328    ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " duration (Dense)            (None, 8)                    2056      ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " offset (Dense)              (None, 6)                    1542      ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " pitch (Dense)               (None, 88)                   22616     ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1417062 (5.41 MB)\n",
      "Trainable params: 1417062 (5.41 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = inputs[0].shape\n",
    "learning_rate = 0.005\n",
    "\n",
    "inp = tf.keras.Input(input_shape)\n",
    "lstm = tf.keras.layers.LSTM(512)(inp)\n",
    "drop = tf.keras.layers.Dropout(0.5)(lstm)\n",
    "dense = tf.keras.layers.Dense(256)(drop)\n",
    "out = {\n",
    "    \"pitch\": tf.keras.layers.Dense(NUM_PIANO_KEYS, name = \"pitch\", activation = \"softmax\")(dense),\n",
    "    \"duration\": tf.keras.layers.Dense(len(duration_map), name = \"duration\", activation = \"softmax\")(dense),\n",
    "    \"offset\": tf.keras.layers.Dense(len(offset_map), name = \"offset\", activation = \"softmax\")(dense),\n",
    "}\n",
    "\n",
    "model = tf.keras.Model(inp, out)\n",
    "\n",
    "model.compile(\n",
    "    loss = \"categorical_crossentropy\",\n",
    "    loss_weights = {\n",
    "        'pitch': 1.0,\n",
    "        'step': 1.0,\n",
    "        'duration':1.0,\n",
    "    },\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate),\n",
    "    metrics = [\"accuracy\", \"accuracy\", \"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5147e22",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer 'lstm_cell' expected 3 variables, but received 0 variables during loading. Expected: ['lstm_1/lstm_cell/kernel:0', 'lstm_1/lstm_cell/recurrent_kernel:0', 'lstm_1/lstm_cell/bias:0']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./weights/single_piece/weights.weights.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer.py:3539\u001b[0m, in \u001b[0;36mLayer.load_own_variables\u001b[1;34m(self, store)\u001b[0m\n\u001b[0;32m   3537\u001b[0m all_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainable_weights \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_trainable_weights\n\u001b[0;32m   3538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(store\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_vars):\n\u001b[1;32m-> 3539\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3540\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(all_vars)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m variables, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3541\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut received \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3542\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(store\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m variables during loading. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3543\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m[v\u001b[38;5;241m.\u001b[39mname\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mv\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mall_vars]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3544\u001b[0m     )\n\u001b[0;32m   3545\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(all_vars):\n\u001b[0;32m   3546\u001b[0m     \u001b[38;5;66;03m# TODO(rchao): check shapes and raise errors.\u001b[39;00m\n\u001b[0;32m   3547\u001b[0m     v\u001b[38;5;241m.\u001b[39massign(store[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mValueError\u001b[0m: Layer 'lstm_cell' expected 3 variables, but received 0 variables during loading. Expected: ['lstm_1/lstm_cell/kernel:0', 'lstm_1/lstm_cell/recurrent_kernel:0', 'lstm_1/lstm_cell/bias:0']"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"./weights/single_piece/weights.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996287e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 04:56:27.038130: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 506612400 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m179/644\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:21\u001b[0m 562ms/step - duration_accuracy: 0.4732 - duration_loss: 1.8730 - loss: 7.5003 - offset_accuracy: 0.5096 - offset_loss: 1.5183 - pitch_accuracy: 0.0402 - pitch_loss: 4.1089"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 15\n",
    "\n",
    "history = model.fit(\n",
    "    x = inputs,\n",
    "    y = {\"pitch\": note_outputs, \"duration\": duration_outputs, \"offset\": offset_outputs},\n",
    "    epochs = epochs,\n",
    "    callbacks = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor = 'loss',\n",
    "        patience = 10,\n",
    "        verbose = 1,\n",
    "        restore_best_weights = True),\n",
    "    validation_split = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f88853",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.epoch, history.history['loss'], label='total train loss')\n",
    "plt.plot(history.epoch, history.history['val_loss'], label='total validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93509d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.epoch, history.history['duration_accuracy'], label='train duration accuracy')\n",
    "plt.plot(history.epoch, history.history['val_duration_accuracy'], label='validation duration accuracy')\n",
    "\n",
    "plt.plot(history.epoch, history.history['offset_accuracy'], label='train offset accuracy')\n",
    "plt.plot(history.epoch, history.history['val_offset_accuracy'], label='validation offset accuracy')\n",
    "\n",
    "plt.plot(history.epoch, history.history['pitch_accuracy'], label='train pitch accuracy')\n",
    "plt.plot(history.epoch, history.history['val_pitch_accuracy'], label='validation pitch accuracy')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "71cf73b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates 50 random notes\n",
    "seed_notes = []\n",
    "for i in range(50):\n",
    "    pitch_index = random.randint(0, NUM_PIANO_KEYS - 1)\n",
    "    pitch = np.zeros(NUM_PIANO_KEYS)\n",
    "    pitch[pitch_index] = 1\n",
    "    \n",
    "    duration_index = random.randint(0, len(duration_map) - 1)\n",
    "    duration = np.zeros(len(duration_map))\n",
    "    duration[duration_index] = 1\n",
    "    \n",
    "    offset_index = random.randint(0, len(offset_map) - 1)\n",
    "    offset = np.zeros(len(offset_map))\n",
    "    offset[offset_index] = 1\n",
    "    \n",
    "    seed_notes.append(np.concatenate([pitch, duration, offset]))\n",
    "    \n",
    "seed_notes = np.asarray(seed_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8118efb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div id=\"midiPlayerDiv60392\"></div>\n",
       "        <link rel=\"stylesheet\" href=\"https://cuthbertLab.github.io/music21j/css/m21.css\">\n",
       "        \n",
       "        <script\n",
       "        src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"\n",
       "        ></script>\n",
       "    \n",
       "        <script>\n",
       "        function midiPlayerDiv60392_play() {\n",
       "            const rq = require.config({\n",
       "                paths: {\n",
       "                    'music21': 'https://cuthbertLab.github.io/music21j/releases/music21.debug',\n",
       "                }\n",
       "            });\n",
       "            rq(['music21'], function(music21) {\n",
       "                mp = new music21.miditools.MidiPlayer();\n",
       "                mp.addPlayer(\"#midiPlayerDiv60392\");\n",
       "                mp.base64Load(\"data:audio/midi;base64,TVRoZAAAAAYAAQACJ2BNVHJrAAAAFAD/UQMHoSAA/1gEBAIYCM5g/y8ATVRyawAAAdoA/wMAAOAAQISnIJBIWqcwkGZajRCASACteIBmAOI4kD1azmCAPQAAkGZa9hCAZgCnMJBNWpNYgE0AgYlokERak1iARACDxGiQIFqnMIAgAIHEcJBsWqcwkD5ak1iAPgDiOIBsAILiMJBRWrsIgFEAg504kDtatECAOwCBt2CQM1qTWIAzALsIkFBapzCQVlqTWIBWALsIkDBapzCAUAAAgDAAAJBnWs5ggGcAzmCQNFqnMIA0AACQUFq7CIBQAIGxGJAlWvYQgCUApzCQX1q0QIBfAJogkEBauwiAQADiOJArWs5gkCxauwiALACTWIArAACQNlrOYIA2AIGdQJAwWqcwkBpak1iAMACgaIAaAIOkAJAXWqcwgBcAAJAVWoGdQIAVAIK7AJBiWvYQgGIApzCQXFq7CIBcAIOdOJAgWrRAgCAAg6QAkFFapzCAUQCDsRCQM1rOYJBaWqcwgDMAk1iAWgDiOJBcWpNYgFwAuwiQHFrOYJBPWs5ggBwAAJAkWrRAgCQAmiCATwCDiWCQI1qnMIAjAIHEcJBgWrRAgGAAg6QAkGJagZ1AgGIAAJBEWrsIgEQAk1iQMVq0QIAxAOkAkCVazmCQKFqTWIAoAJNYgCUAzmD/LwA=\");\n",
       "            });\n",
       "        }\n",
       "        if (typeof require === 'undefined') {\n",
       "            setTimeout(midiPlayerDiv60392_play, 2000);\n",
       "        } else {\n",
       "            midiPlayerDiv60392_play();\n",
       "        }\n",
       "        </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# select seed notes from training music\n",
    "# seed_notes = inputs[0]\n",
    "\n",
    "# turns the seed note vectors back into actual music21 notes\n",
    "chord_builder = []\n",
    "note_stream = []\n",
    "offset = 0\n",
    "\n",
    "for g in reversed(seed_notes):\n",
    "    n = note.Note(np.argmax(g[:NUM_PIANO_KEYS]) + A0_MIDI_OFFSET)\n",
    "    str_duration = reverse_duration[np.argmax(g[NUM_PIANO_KEYS : NUM_PIANO_KEYS + len(duration_map)])]\n",
    "    try:\n",
    "        n.quarterLength = float(str_duration)\n",
    "    except:\n",
    "        n.quarterLength = Fraction(str_duration)\n",
    "    # if offset is 0, stores it so that it can be added to a chord\n",
    "    offset = reverse_offset[np.argmax(g[-1 * len(offset_map):])]\n",
    "    if offset == 0:\n",
    "        chord_builder.append(n)\n",
    "    elif len(chord_builder) == 0:\n",
    "        note_stream.append((n, offset))\n",
    "    else:\n",
    "        note_stream.append((chord.Chord(chord_builder), offset))\n",
    "        chord_builder = []\n",
    "if len(chord_builder) == 1:\n",
    "    note_stream.append((chord_builder[0], 0))\n",
    "elif len(chord_builder) > 1:\n",
    "    note_stream.append((chord.Chord(chord_builder), 0))\n",
    "note_stream.reverse()\n",
    "\n",
    "seed_stream = stream.Stream()\n",
    "previous_offset = 0\n",
    "for n, off in note_stream:\n",
    "    previous_offset += off\n",
    "    seed_stream.insert(previous_offset, n)\n",
    "seed_stream.show(\"midi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "46a5a15a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n"
     ]
    }
   ],
   "source": [
    "# generates new notes by adding the newly generated note to the end of the seed notes\n",
    "num_notes = 100\n",
    "generated_notes = []\n",
    "for i in range(num_notes):\n",
    "    new_note = model.predict(tf.expand_dims(seed_notes, 0))\n",
    "    new_input = np.concatenate([new_note[\"pitch\"], new_note[\"duration\"], new_note[\"offset\"]], axis = 1)\n",
    "    generated_notes.append(new_note)\n",
    "    seed_notes = np.delete(seed_notes, 0, axis = 0)\n",
    "    seed_notes = np.append(seed_notes, new_input, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bbab1f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div id=\"midiPlayerDiv60596\"></div>\n",
       "        <link rel=\"stylesheet\" href=\"https://cuthbertLab.github.io/music21j/css/m21.css\">\n",
       "        \n",
       "        <script\n",
       "        src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"\n",
       "        ></script>\n",
       "    \n",
       "        <script>\n",
       "        function midiPlayerDiv60596_play() {\n",
       "            const rq = require.config({\n",
       "                paths: {\n",
       "                    'music21': 'https://cuthbertLab.github.io/music21j/releases/music21.debug',\n",
       "                }\n",
       "            });\n",
       "            rq(['music21'], function(music21) {\n",
       "                mp = new music21.miditools.MidiPlayer();\n",
       "                mp.addPlayer(\"#midiPlayerDiv60596\");\n",
       "                mp.base64Load(\"data:audio/midi;base64,TVRoZAAAAAYAAQACJ2BNVHJrAAAAFAD/UQMHoSAA/1gEBAIYCM5g/y8ATVRyawAAAjUA/wMAAOAAQM5gkDZaAJAlWqcwkEBapzCAQAAAkDlapzCAOQAAkExapzCATAAAkEVapzCARQAAkEVapzCANgAAgCUAAIBFAACQTFoAkEVapzCATAAAgEUAAJBFWqcwgEUAAJA9WgCQPVqnMIA9AACAPQAAkExapzCATAAAkDlaAJBFWqcwgDkAAIBFAACQRVqnMIBFAACQLVoAkDtaAJBHWgCQRVqnMJA5WqcwgDkAAJA5WgCQRVqnMIA5AACARQAAkEVapzCARQAAkEJaAJBOWqcwgEIAAIBOAACQPloAkEpapzCALQAAgDsAAIBHAACARQAAgD4AAIBKAACQLVoAkEBaAJBMWgCQRVqnMJBAWqcwgEAAAJBJWqcwgEkAAJBJWqcwgEkAAJBFWqcwgEUAAJAtWgCQOVoAkExapzCALQAAgEAAAIBMAACARQAAgC0AAIA5AACATAAAkDFapzCAMQAAkDRaAJA5WgCQTFqnMIA0AACAOQAAgEwAAJA5WqcwgDkAAJA9WqcwgD0AAJBAWqcwgEAAAJAtWgCQOVoAkEVapzCALQAAgDkAAIBFAACQMVqnMIAxAACQO1oAkDlaAJBFWqcwgDsAAIA5AACARQAAkD1aAJBMWgCQPVqnMIA9AACATAAAgD0AAJA9WgCQRVqnMIA9AACARQAAkEJapzCAQgAAkD1aAJBAWqcwgD0AAIBAAACQQFqnMIBAAACQQFqnMIBAAACQPlqnMIA+AM5g/y8A\");\n",
       "            });\n",
       "        }\n",
       "        if (typeof require === 'undefined') {\n",
       "            setTimeout(midiPlayerDiv60596_play, 2000);\n",
       "        } else {\n",
       "            midiPlayerDiv60596_play();\n",
       "        }\n",
       "        </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# turns the generated notes into music21 notes\n",
    "chord_builder = []\n",
    "note_stream = []\n",
    "offset = 0\n",
    "temperature = 1.5\n",
    "for i in reversed(range(len(generated_notes))):\n",
    "    g = generated_notes[i]\n",
    "    probs = g[\"pitch\"].reshape(-1)\n",
    "    pitch_idx = np.random.choice(len(probs), p=probs**temperature/np.sum(probs**temperature))\n",
    "\n",
    "    n = note.Note(pitch_idx + A0_MIDI_OFFSET)\n",
    "    try:\n",
    "        n.quarterLength = float(reverse_duration[np.argmax(g[\"duration\"])])\n",
    "    except:\n",
    "        n.quarterLength = Fraction(reverse_duration[np.argmax(g[\"duration\"])])\n",
    "    # if offset is 0, stores it so that it can be added to a chord\n",
    "    offset = reverse_offset[np.argmax(g[\"offset\"])]\n",
    "    if offset == 0:\n",
    "        chord_builder.append(n)\n",
    "    elif len(chord_builder) == 0:\n",
    "        note_stream.append((n, offset))\n",
    "    else:\n",
    "        note_stream.append((chord.Chord(chord_builder), offset))\n",
    "        chord_builder = []\n",
    "if len(chord_builder) == 1:\n",
    "    note_stream.append((chord_builder[0], 0))\n",
    "elif len(chord_builder) > 1:\n",
    "    note_stream.append((chord.Chord(chord_builder), 0))\n",
    "note_stream.reverse()\n",
    "\n",
    "s = stream.Stream()\n",
    "previous_offset = 0\n",
    "for n, off in note_stream:\n",
    "    previous_offset += off\n",
    "    s.insert(previous_offset, n)\n",
    "s.show(\"midi\")\n",
    "\n",
    "# writes the midi file of the output\n",
    "s.write(\"midi\", \"output.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0bc04907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output.mid'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# writes the midi file of the output\n",
    "s.write(\"midi\", \"output.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5ffe1abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"./weights/multiple_pieces/weights.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "299659c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 0, 0.5: 1, 1.0: 2, 2.0: 3, 3.0: 4, 6.0: 5}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e0502bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0.25': 0,\n",
       " '0.5': 1,\n",
       " '0.75': 2,\n",
       " '1.0': 3,\n",
       " '1.5': 4,\n",
       " '2.0': 5,\n",
       " '2/3': 6,\n",
       " '3.0': 7}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duration_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "82827b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save offset and duration maps\n",
    "with open('weights/multiple_pieces/offset_map.txt', \"w\") as f:\n",
    "    for k in offset_map:\n",
    "        f.write(f\"{k}:{offset_map[k]}\\n\")\n",
    "        \n",
    "with open('weights/multiple_pieces/duration_map.txt', \"w\") as f:\n",
    "    for k in duration_map:\n",
    "        f.write(f\"{k}:{duration_map[k]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d11d9084",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_map = dict()\n",
    "with open(\"weights/single_piece/offset_map.txt\") as f:\n",
    "    for line in f:\n",
    "        key, value = line.strip().split(\":\")\n",
    "        try:\n",
    "            offset_map[float(key)] = int(value)\n",
    "        except:\n",
    "            offset_map[Fraction(key)] = int(value)\n",
    "reverse_offset = {offset_map[k]:k for k in offset_map}\n",
    "duration_map = dict()\n",
    "with open(\"weights/single_piece/duration_map.txt\") as f:\n",
    "    for line in f:\n",
    "        key, value = line.strip().split(\":\")\n",
    "        try:\n",
    "            duration_map[float(key)] = int(value)\n",
    "        except:\n",
    "            duration_map[Fraction(key)] = int(value)\n",
    "reverse_duration = {duration_map[k]:k for k in duration_map}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cd9859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to read in previous dictionaries, used for when transfer learning\n",
    "# so that the encodings were consistent between models\n",
    "# offset_map = dict()\n",
    "# with open('mappings/duration_map.txt') as json_file:\n",
    "#     duration_map = json.load(json_file)  \n",
    "# reverse_duration = dict()\n",
    "# with open('mappings/reverse_duration.txt') as f:\n",
    "#     for line in f:\n",
    "#         key, value = line.strip().split(\":\")\n",
    "#         reverse_duration[int(key)] = value\n",
    "# reverse_offset = dict()\n",
    "# with open('mappings/reverse_offset.txt') as f:\n",
    "#     for line in f:\n",
    "#         key, value = line.strip().split(\":\")\n",
    "#         reverse_offset[int(key)] = float(value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
